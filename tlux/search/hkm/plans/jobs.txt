from typing import Iterable
from .fs import FileSystem

# Job status tracker / container. Process ID, RAM, CPU stats, signals
# for killing, pausing, resuming. This object is serializable and
# reloadable to recover reference to a specific job.
class Job:
    pass

# Function for spawning a job. Optional list of dependencies, if
# provided, enqueues job launcher in a way that can be triggered by
# the last dependency to finish.
def spawn_job(main_function: str, dependencies: Iterable[Job] = (), *args, **kwargs) -> Job:
    pass



# Have jobs claim "IDs" using the file system and a job info directory.
# Jobs dump standard output and standard error to files in their job directory.
# Jobs coordinate out of a directory in a file system, that looks like:
#  jobs/
#    ids/
#      000000000/
#      000000001/
#      000000002/
#      000000003/
#      ..
#    finished/
#      000000001/
#        job_config
#        exec_function
#        exec_args
#        stdout
#        stderr
#        hostname/
#        downstream_jobs/
#          000000002/
#          ...
#      ...
#    failed/
#      000000000/
#        job_config
#        exec_function
#        exec_args
#        stdout
#        stderr
#        hostname/
#      ...
#    running/
#      000000002/
#        job_config
#        exec_function
#        exec_args
#        stdout
#        stderr
#        hostname/
#          process_identifier
#          resource_limits
#        upstream_jobs/
#          000000001/
#      ...
#    next/
#      000000002/
#        000000003/
#    waiting/
#      000000003/
#        job_config
#        exec_function
#        exec_args
#        upstream_jobs/
#          000000001/
#          000000002/
#      ...
# 
# 
# Assume that the executable function is a python module path, and args and kwargs are passed via serialization through the command line.
# Assume that all jobs share a sufficiently similar environment that commands are reproducible.
# Assume that the files and directories in the filesystem have typical metadata attached (create, modify, access).
# Assume that creating a directory on the file system is atomic and race-safe.
# Assume that moving a directoroy on the file system is atomic and race-safe.
# When creating a new job, a job identifer "id" directory is atomically created (if successful, ID claimed)
#   In general, IDs should be generated in a way that sufficiently minimizes collisions, like using the last nine digits of a 100-microsecond-level counter.
# When a new job is spwaned without dependencies, it goes into the "running" directory.
# When a new job is spawned with dependencies, it goes into the "waiting" directory.
#   It has a subdirectory "upstream_jobs" that contains (empty) subdirectories for all job IDs.
#   It ensures that each upstream job has a directory in the "next" directory, and within that its own ID is an (empty) subdirectory.
# When a job finishes it:
#   moves its own directory from "running" to "finished" if it succeeded (exit code 0)
#   moves its own directory from "running" to "failed" if it failed (any nonzero exit code)
#   lists the "next" directory to see if its own ID is present and if so it adds all contained job IDs to its own "downstream_jobs" directory,
#   removes its own "next" directory,
#   for each downstream job it:
#     lists the "waiting/XXXXXXXXX/upstream_jobs/" directory for all downstream jobs,
#     lists the "running" directory to see if any of those jobs are active and if any are active it exits,
#     if no other upstream jobs are active, it tries to move the job directory from "waiting" to "running"
#     if the move succeeds, it is assumed this job singularly succeeded and it initiates execution
# A side-process runs for global stability. The following should be done periodically:
#   Cleaning of old "ids", "finished", and "failed" to cap listing sizes.
#   State-check on "running" jobs, moving them to "failed" if the "hostname" reports no such active PID and performing "job-finished" tasks.
# 
# Thoughts that are not yet well formed, but possible:
#   Multiple hosts can register themselves into the job executor pool for a "jobs" directory.
#   There is a "services/" directory that contains references to jobs that should always be running.
#   Each job has a "resource_config" that includes projected second-level resource utilization over the life of the job,
#    by default is flat, but for recurring jobs can average histories to get more accurate.
#   Side process looks at projected forward resource utilization of active hosts, picks host in way to
#    minimize peak memory utilization (would cause hard crash) and compute utilization.
#   Alternatively, active hosts claim "running" jobs by checking to see if they can start a job safely
#    given their current resource utilization.



